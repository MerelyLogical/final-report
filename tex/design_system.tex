\section{System-level Design}

\subsection{Testbench Architecture}
The design of the verification system is the major engineering challenge of this project.
% REVISIT: this sentence should be moved to intro for overall motivation of project.
While there have been many similar performance analyses done on hybrid SoCs before, each of them used their own, usually ad hoc, testbench design~\cite{Shi1}~\cite{Li1}.
As such, most testbench are not designed to be scalable or portable, serving only what they are built for.
In this project, I shall use a generic structure inspired by that of an agent in Universal Verification Methodology (UVM).

Before UVM, integrated circuit designs were verified with methodologies developed independently by stimulator vendors such as Cadence, Mentor Graphics, and Synopsys.
In an effort to unify for greater efficiency, the standards organisation of the Electronic Design Automation (EDA) industry, Accellera, established UVM with support from multiple vendors.
It provided a common structure for verification, with class libraries that made building and running a testbench a significantly smoother experience.
The agent is a container in UVM that emulates and verifies DUTs~\cite{Accellera1}.
While this project is in no position to achieve what UVM has done, I do hope that this testbench would have an easily modifiable structure that will make the process of testing similar future designs slightly simpler.

\begin{figure}[H]
  \centering
  \input{illu/tb_block}
  \caption{Block diagram of the testbench design}
  \label{Block}
\end{figure}

The test script running on the HPS will read from a configuration file, and sends the corresponding test configuration to the driver.
The driver then pulls a stream of random data generated by the randomiser, and convert them to meaningful test inputs according to specification.
The test output will be watched by the monitor, reporting the results to the scoreboard, which keeps track of them.
The Monitor make uses of reference designs functionally identical to the DUT, which allows identification of false outputs from the DUT.
Multiple instances of the reference designs means multiple test data can be processed in parallel, so that the reference design can have a relaxed frequency requirement.
The scoreboard collects the results from the monitor and writes them to memory locations accessible from the other side of the bridge.
These memory locations are read by the test scripts, providing results and other useful information to the user.
The design and implementation of each individual hardware and software module will be elaborated in detail in the following chapters.

\subsection{User Interface}

For this evaluation framework to be meaningful, it has to attract users by being easy to configure and run.
To achieve this, 
% REVISIT: easy change of parameter in qsys, configuration file interface, maybe someof this is more like inplementation
