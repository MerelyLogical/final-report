\chapter{System-level Design}

\section{Testbench Architecture}
The design of the verification system is the major engineering challenge of this project.
% REVISIT: this sentence should be moved to intro for overall motivation of project.
While there have been many similar performance analyses done on hybrid SoCs before, each of them used their own, usually ad hoc, testbench design~\cite{Shi1}~\cite{Li1}.
As such, most testbench are not designed to be scalable or portable, serving only what they are built for.
In this project, I shall use a generic structure inspired by that of an agent in Universal Verification Methodology (UVM).

Before UVM, integrated circuit designs were verified with methodologies developed independently by stimulator vendors such as Cadence, Mentor Graphics, and Synopsys.
In an effort to unify for greater efficiency, the standards organisation of the Electronic Design Automation (EDA) industry, Accellera, established UVM with support from multiple vendors.
It provided a common structure for verification, with class libraries that made building and running a testbench a significantly smoother experience.
The agent is a container in UVM that emulates and verifies DUTs~\cite{Accellera1}.
While this project is in no position to achieve what UVM has done, I do hope that this testbench would have an easily modifiable structure that will make the process of testing similar future designs slightly simpler.

\begin{figure}[H]
  \centering
  \input{illu/tb_block}
  \caption{Block diagram of the testbench design}
  \label{Block}
\end{figure}

The test script running on the HPS will read from a configuration file, and sends the corresponding test configuration to the driver.
The driver then pulls a stream of random data generated by the randomiser, and convert them to meaningful test inputs according to specification.
The test output will be watched by the monitor, reporting the results to the scoreboard, which keeps track of them.
The Monitor make uses of reference designs functionally identical to the DUT, which allows identification of false outputs from the DUT.
Multiple instances of the reference designs means multiple test data can be processed in parallel, so that the reference design can have a relaxed frequency requirement.
The scoreboard collects the results from the monitor and writes them to memory locations accessible from the other side of the bridge.
These memory locations are read by the test scripts, providing results and other useful information to the user.
The design and implementation of each individual hardware and software module will be elaborated in detail in the following chapters.

\section{User Interface}

For this evaluation framework to be meaningful, it has to attract users by being easy to configure and run.
To achieve this, in addition to the functional designs, both hardware and software need to be designed with the user's experience in mind.
% REVISIT: easy change of parameter in qsys, configuration file interface, maybe someof this is more like implementation

\section{Hardware Choice}
The system itself will be built on a Cyclone V SX SoC Development Board from Intel~\cite{Intel1}.

\begin{figure}[H]
  \centering
  \includegraphics[width=10cm]{img/SoCStructure}
  \caption{Structure of the System-on-Chip}
  \label{SoCStructure}
\end{figure}

The 5CSXFC6D6F31C6N SoC has an Arm Cortex-A9 MPCore accompanied by Intel's 28nm FPGA fabric~\cite{Altera1}.
The FPGA is necessary for implementing the hardware design and obtaining empirical results for the project.
% maybe hybrid architecture soc makes programming it harder and it could % be used as a negative point 
While an FPGA without an embedded CPU will be enough for this project to work, having an Hard Processor System (HPS) on the same chip is useful as the test software can run on it.
The HPS is a separate piece of hardware that distinguishes itself from a soft processor, such as the Nios II, a processor programmed onto the FPGA itself.
With this additional capacity, a better user interface can thus be constructed with more detailed, on-the-fly control of the FPGA.
This means setting up the testbench will only require programming the design into the FPGA, followed by running the test script on the HPS.
The product will thus be self-contained.
It will be more accessible as no additional setup is required for the user.

It should be noted that Xilinx offers similar boards as well.
Its Zynq SoC family has a very comparable structure as they too integrate the software programmability of an Arm processor with the hardware possibility of an FPGA.
For example, similar to the Cyclone V SX, Zynq-7000S features an Arm Cortex-A9
coupled with a Xilinx 28nm FPGA~\cite{Xilinx1}.
As such, a board like the ZedBoard~\cite{Xilinx2} could be just as viable for this project.

As there are very few significant functional differences between the two brands, I shall initially explore with the Intel board, simply for its availability and my familiarity with their development tools.
Due to the architectural differences between the logic elements between Xilinx and Altera FPGAs~\cite{Scekic1}, the performances on the two boards are not necessarily identical.
Once the project has progressed to a point where the system design is mature and tested, the Xilinx alternative can be explored as an extension.

\section{Software Choice}
The software choice follows closely with the hardware choice in this project.
To develop for Intel FPGAs, Quartus has to be used.
The version picked is arbitrary as there are not many functional differences between the versions that will be critical to the project.
As Quartus Prime 16.0 is the version installed in the computers in the department, I will use the same version simply for convenience.
This naturally means the hardware system will be built with the system integration tool that comes with Quartus -- Qsys.

The Qsys software is designed to be used for integrating different hardware modules into a system.
As such, it will be used as the interface for the two parallel projects.

While an HLS language could be used, in this design it suffers from a few problems and does not offer enough benefits to justify its use.
Usually HLS is preferred for developing complex algorithms, because compilers can optimise them into RTL much better than humans.
However, the resulting RTL would be unreadable, making directly controlling or debugging at the hardware level nearly impossible.
The interfaces require detailed control of the actual hardware and the rest of the testbench has a lot of control path work and direct manipulation on the data bits.
It is therefore not worth it to use HLS and as such, this design will be written in Verilog.

Other than the hardware design tools, there is some freedom of choice on the HPS side of the project.
The test will be built with Python, which will be running on an Ubuntu system that is installed on the HPS.
This choice is made as there are previous unrelated projects on the same development board, which means a lot of time can be saved on tedious setup works such as getting an operating system booting.

Git is used as the version control system for this project.
A list of repositories on GitHub holds all files related to this project.
Readme files on the repositories and the commit histories will serve as digital logbooks to this project.
A copy of the user guide will also be made available on the GitHub repository.